{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Remittance_Weekly_Reconciliation_File.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophiaU/Git_DoD_Remittance/blob/main/Remittance_Weekly_Reconciliation_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVfZVM5-by6K"
      },
      "source": [
        "# install and import pygsheets\n",
        "!pip install pygsheets\n",
        "import pygsheets\n",
        "\n",
        "#  Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# connect google sheets\n",
        "import gspread\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "import json\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# with open('service_account.json') as source:\n",
        "#    info = json.load(source)\n",
        "# credentials = service_account.Credentials.from_service_account_info(info)\n",
        "\n",
        "# client = pygsheets.authorize(service_account_file='service_account.json')\n",
        "\n",
        "# import pandas\n",
        "import pandas as pd\n",
        "from functools import reduce\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397mFw4x6n7E"
      },
      "source": [
        "Combine Performance File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x_lqgSD6EZQ"
      },
      "source": [
        "# Append all files in folder into a listframe\n",
        "\n",
        "listframe = []\n",
        "\n",
        "weekname = 'Jul 05'\n",
        "fileid = '1622D4YEaxFgT_6oGCPesUReORnys57jD'\n",
        "\n",
        "folder = drive.ListFile({'q': \"title contains '\"+weekname+\"' and not title contains '(7)' and not title contains '(6)' and '\"+fileid+\"' in parents and mimeType = 'text/csv' and trashed = false \"}).GetList()\n",
        "for file in folder:\n",
        "  print(file['title'])\n",
        "\n",
        "  # download\n",
        "  fileDownloaded = drive.CreateFile({'id':file['id']})\n",
        "\n",
        "  # load\n",
        "  fileDownloaded.GetContentFile('performance.csv')\n",
        "\n",
        "  # read\n",
        "  df = pd.read_csv('performance.csv', delimiter=',' )\n",
        "\n",
        "  # append\n",
        "  listframe.append(df)\n",
        "\n",
        "# combine all files in the list into a dataframe\n",
        "wkperffile = pd.concat(listframe)\n",
        "\n",
        "# pick only name, trips and supply hours\n",
        "performancefile = wkperffile[['Name','Trips','Hours online']]\n",
        "\n",
        "# capitalize the name column\n",
        "performancefile['Name'] = pd.Series(performancefile['Name']).str.title()\n",
        "\n",
        "# convert hour online to just hours\n",
        "performancefile['Hours online'] = pd.to_timedelta(performancefile['Hours online']).dt.total_seconds()/3600\n",
        "\n",
        "# sum trips and hours by names\n",
        "performancefile = performancefile.groupby(['Name']).sum().reset_index()\n",
        "\n",
        "print(performancefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eSrxcOuVd4E"
      },
      "source": [
        "Combine Payments file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_xQ3248Vj0t"
      },
      "source": [
        "#  Append all files in folder into a listframe\n",
        "paymentslistframe = []\n",
        "\n",
        "fileid = '15ylXHnFS3bh-2IbSboSrGbCLL3zW6bj9'\n",
        "\n",
        "folder = drive.ListFile({'q': \"title contains '\"+weekname+\"' and not title contains '(7)' and not title contains '(6)' and '\"+fileid+\"' in parents and mimeType = 'text/csv' and trashed = false \"}).GetList()\n",
        "for file in folder:\n",
        "  print(file['title'])\n",
        "\n",
        "  # download\n",
        "  fileDownloaded = drive.CreateFile({'id':file['id']})\n",
        "\n",
        "  # load\n",
        "  fileDownloaded.GetContentFile('payments.csv')\n",
        "\n",
        "  # read\n",
        "  df = pd.read_csv('payments.csv', delimiter=',' )\n",
        "\n",
        "  # append\n",
        "  paymentslistframe.append(df)\n",
        "\n",
        "# combine all files in the list into a dataframe\n",
        "combinedPayments = pd.concat(paymentslistframe)\n",
        "\n",
        "# concatenate the names\n",
        "combinedPayments['Name'] = combinedPayments['firstName'] + \" \" + combinedPayments['lastName']\n",
        "combinedPayments['Name'] = pd.Series(combinedPayments['Name']).str.title()\n",
        "combinedPayments = combinedPayments[['Name','driverUUID', 'tripUUID', 'firstName', 'lastName', 'amount','timestamp', 'itemType', 'description', 'disclaimer']]\n",
        "\n",
        "# pick only fullname, amount and itemtype\n",
        "paymentsfile = combinedPayments[['Name','driverUUID','amount','itemType']]\n",
        "\n",
        "# get net earnings\n",
        "# drop cash collected itemtype\n",
        "netEarnings = paymentsfile.loc[paymentsfile['itemType'] != 'cash_collected']\n",
        "\n",
        "# drop payouts itemtype\n",
        "netEarnings = netEarnings.loc[netEarnings['itemType'] != 'payouts']\n",
        "\n",
        "# sum amounts by names to get the net earnings per driver\n",
        "netEarnings = netEarnings.groupby(['driverUUID']).sum().reset_index()\n",
        "netEarnings.columns = ['driverUUID','Net Earnings']\n",
        "# netEarnings['Name'] = pd.Series(netEarnings['Name']).str.title()\n",
        "netEarnings.head(400)\n",
        "\n",
        "# get total cash collected\n",
        "# get cash collected itemtype\n",
        "cashCollected = paymentsfile.loc[paymentsfile['itemType'] == 'cash_collected']\n",
        "\n",
        "# sum amounts by names to get the cash collected per driver\n",
        "cashCollected = cashCollected.groupby(['driverUUID']).sum().reset_index()\n",
        "cashCollected.columns = ['driverUUID', 'Cash Collected']\n",
        "#cashCollected['Name'] = pd.Series(cashCollected['Name']).str.title()\n",
        "\n",
        "cashCollected.head(400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsTX16-yfvFi"
      },
      "source": [
        "#Add Driver Uber ID to Performance file\n",
        "\n",
        "uniqueID = combinedPayments.groupby(['Name','driverUUID']).sum().reset_index()\n",
        "\n",
        "# uniqueID = combinedPayments.drop_duplicates(\n",
        "#   subset = ['Name', 'driverUUID'],\n",
        "#   keep = 'last').reset_index(drop = True)\n",
        "\n",
        "performancefile1 = pd.merge(performancefile, uniqueID[['Name','driverUUID']], on='Name', how='left')\n",
        "performancefile1 = performancefile1[['Name','Trips','Hours online','driverUUID']]\n",
        "performancefile1 = performancefile1.groupby(['driverUUID']).sum().reset_index()\n",
        "performancefile1\n",
        "\n",
        "\n",
        "# NameCheck = performancefile1.query('driverUUID == \"de90e988-5c1d-4ee7-ae7d-0a1418cdd111\"')\n",
        "# NameCheck = performancefile1.query('Name == \"Onyeka Aigbaze\"')        # Isiaq Jamiu Akanbi\n",
        "# NameCheck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-H0ZCtBZGLH"
      },
      "source": [
        "netEarnings.head(400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvG6dTT3nSbN"
      },
      "source": [
        "# # export to csv\n",
        "# netearnings_csv = netEarnings.to_csv( \"netearnings.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "# file2 = drive.CreateFile({'parents': [{'id': '15w_MeKLpCE2hs8-Vvs4IUBH_sZ8e3qbP'}]})\n",
        "# file2.SetContentFile(\"netearnings.csv\")\n",
        "# file2.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alBu1wzclRnk"
      },
      "source": [
        "# Write combined payments file to google sheets\n",
        "# combinedPayments = combinedPayments[['Name','driverUUID', 'tripUUID', 'firstName', 'lastName', 'amount','timestamp', 'itemType', 'description', 'disclaimer']]\n",
        "# combinedPayments = combinedPayments.fillna(\"\")\n",
        "# dtoSheet = client.open_by_key('1cxkEP4YqeVnQ4guhn8D-NMUxJdH4YRF7zX9v9IV3WhM')\n",
        "# wkspaymentfile = dtoSheet[1]\n",
        "\n",
        "# wkspaymentfile.set_dataframe(combinedPayments,(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvQclpmcZS2K"
      },
      "source": [
        "performancefile1.head(400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGhCeehXrHX6"
      },
      "source": [
        "# performance_csv = performancefile.to_csv( \"performance.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "# file2 = drive.CreateFile({'parents': [{'id': '15w_MeKLpCE2hs8-Vvs4IUBH_sZ8e3qbP'}]})\n",
        "# file2.SetContentFile(\"performance.csv\")\n",
        "# file2.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1gZJNVgSsiz"
      },
      "source": [
        "Get Moove Details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "BRYafP4ktsv6",
        "outputId": "db733300-7087-479f-f21f-e25ebcb102cd"
      },
      "source": [
        "# get moove details\n",
        "mooveDetailList =[]\n",
        "worksheet = gc.open_by_key('1Q3BJcXwRncZiiB3GAYw1CNN-RWOWjt4AyUHxjs_Kztg').sheet1\n",
        "for i in range(2,6):\n",
        "  columns = worksheet.col_values(i)\n",
        "  mooveDetailList.append(columns[1:])\n",
        "\n",
        "# print(mooveDetailList)\n",
        "\n",
        "# convert list to data frame\n",
        "mooveDetails = pd.DataFrame(mooveDetailList)\n",
        "mooveDetails = mooveDetails.T\n",
        "mooveDetails.columns = ['Name','Product','DRN','driverUUID']\n",
        "mooveDetails['Name'] = pd.Series(mooveDetails['Name']).str.title()\n",
        "#print(mooveDetails)\n",
        "mooveDetails"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Product</th>\n",
              "      <th>DRN</th>\n",
              "      <th>driverUUID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Inwang Ubong</td>\n",
              "      <td>income product</td>\n",
              "      <td>DRN000022</td>\n",
              "      <td>4ed6faed-e165-4a8b-8e47-9a24433ddb91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adeola Okusaga</td>\n",
              "      <td>income product</td>\n",
              "      <td>DRN000220</td>\n",
              "      <td>b2e4d5a7-fbae-49a2-be3a-4ba1b9f179f5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Temitope Tayo</td>\n",
              "      <td>income product</td>\n",
              "      <td>DRN000229</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chiegeokwu Amaju</td>\n",
              "      <td>flexi rental</td>\n",
              "      <td>DRN000230</td>\n",
              "      <td>0f23e379-8b69-4233-9497-0ad579a2f60a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adanna Cythia Nwanna</td>\n",
              "      <td>flexi rental</td>\n",
              "      <td>DRN000233</td>\n",
              "      <td>0af65713-855a-4a7f-8d15-5fca9dbfecbb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>Paul Akere Omokaro</td>\n",
              "      <td>DTO-II 48</td>\n",
              "      <td>DRN002663</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>Kelechi Oluwatoba Okorie</td>\n",
              "      <td>DTO-II 48</td>\n",
              "      <td>DRN002662</td>\n",
              "      <td>ba59a846-4044-4fae-84c6-81a9628fd6b7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>Omololu Kehinde Sotonwa</td>\n",
              "      <td>DTO-II 48</td>\n",
              "      <td>DRN002633</td>\n",
              "      <td>a1660b79-4752-4dfd-a79b-3bc14db3163d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>Aimuanmwosa Amos Asemota</td>\n",
              "      <td>DTO-II 48</td>\n",
              "      <td>DRN002654</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>Ijeoma Njoku</td>\n",
              "      <td>flexi rental</td>\n",
              "      <td>DRN002623</td>\n",
              "      <td>e0494b8c-8723-4b0a-a7b2-b486d3bc6bbc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>935 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Name  ...                            driverUUID\n",
              "0                Inwang Ubong  ...  4ed6faed-e165-4a8b-8e47-9a24433ddb91\n",
              "1              Adeola Okusaga  ...  b2e4d5a7-fbae-49a2-be3a-4ba1b9f179f5\n",
              "2               Temitope Tayo  ...                                      \n",
              "3            Chiegeokwu Amaju  ...  0f23e379-8b69-4233-9497-0ad579a2f60a\n",
              "4        Adanna Cythia Nwanna  ...  0af65713-855a-4a7f-8d15-5fca9dbfecbb\n",
              "..                        ...  ...                                   ...\n",
              "930        Paul Akere Omokaro  ...                                      \n",
              "931  Kelechi Oluwatoba Okorie  ...  ba59a846-4044-4fae-84c6-81a9628fd6b7\n",
              "932   Omololu Kehinde Sotonwa  ...  a1660b79-4752-4dfd-a79b-3bc14db3163d\n",
              "933  Aimuanmwosa Amos Asemota  ...                                      \n",
              "934              Ijeoma Njoku  ...  e0494b8c-8723-4b0a-a7b2-b486d3bc6bbc\n",
              "\n",
              "[935 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA4zlbRfn5AH"
      },
      "source": [
        "Virtual Accounts Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwbIA8h5n4dt"
      },
      "source": [
        "fileid = '18oe6VePd_c0cqPkrXI8QfvHixpECOn_Z'\n",
        "\n",
        "folder = drive.ListFile({'q': \"title contains '\"+weekname+\"' and not title contains '(7)' and not title contains '(6)' and '\"+fileid+\"' in parents and mimeType = 'text/csv' and trashed = false \"}).GetList()\n",
        "\n",
        "for file in folder:\n",
        "  print(file['title'])\n",
        "\n",
        "  # download\n",
        "  fileDownloaded = drive.CreateFile({'id':file['id']})\n",
        "\n",
        "  # load\n",
        "  fileDownloaded.GetContentFile('VirtualAccount.csv')\n",
        "\n",
        "  # read\n",
        "  VirtualAccountDF = pd.read_csv('VirtualAccount.csv', delimiter=',' )\n",
        "\n",
        "# select only drn and amount\n",
        "VirtualAcctDF = VirtualAccountDF[['drn','amount']]  \n",
        "VirtualAcctDF.rename(columns={'drn':'DRN'}, inplace=True)\n",
        "\n",
        "# Sum Amount\n",
        "sumVA = VirtualAcctDF.groupby(['DRN']).sum().reset_index()\n",
        "sumVA.rename(columns={'amount':'VA Collections'}, inplace=True)\n",
        "\n",
        "# count amount\n",
        "countVA = VirtualAcctDF.groupby(['DRN']).count().reset_index()\n",
        "countVA.rename(columns={'amount':'VA Transactions'}, inplace=True)\n",
        "\n",
        "print(sumVA)\n",
        "print(countVA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJLeyOnNDnas"
      },
      "source": [
        "# write va to google sheets\n",
        "\n",
        "# reconSheet = client.open_by_key('1hWr33xeKPsgjA5oRjADCFHtH3CkeiebdJ1eMM6IRia0')\n",
        "# wksreconfile = reconSheet[3]\n",
        "\n",
        "# wksreconfile.set_dataframe(sumVA,(1,1))\n",
        "# wksreconfile.set_dataframe(countVA,(1,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e2woJWvpp7v"
      },
      "source": [
        "Days with car Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooOXvC5ZpsY2"
      },
      "source": [
        "# get moove details\n",
        "daysWithCarlList =[]\n",
        "carsWorksheet = gc.open_by_key('1_hFrUFt5qoXbah9tLyQLnbmTZFPzeySYGYBnPjE3eZQ').sheet1\n",
        "for i in range(10,12):\n",
        "  columns = carsWorksheet.col_values(i)\n",
        "  daysWithCarlList.append(columns[1:])\n",
        "\n",
        "# print(mooveDetailList)\n",
        "\n",
        "# convert list to data frame\n",
        "daysWithCar = pd.DataFrame(daysWithCarlList)\n",
        "daysWithCar = daysWithCar.T\n",
        "daysWithCar.columns = ['DRN','Effective Days']\n",
        "daysWithCar['DRN'] = pd.Series(daysWithCar['DRN']).str.strip()\n",
        "daysWithCar = pd.merge(daysWithCar,mooveDetails,how='left', on='DRN')\n",
        "# daysWithCar = daysWithCar.dropna()\n",
        "\n",
        "daysWithCar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeFQe4xEVvg"
      },
      "source": [
        "# write va to google sheets\n",
        "\n",
        "# reconSheet = client.open_by_key('1hWr33xeKPsgjA5oRjADCFHtH3CkeiebdJ1eMM6IRia0')\n",
        "# wksreconfile = reconSheet[3]\n",
        "\n",
        "# wksreconfile.set_dataframe(daysWithCar,(1,7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP7bsluCSm1y"
      },
      "source": [
        "Combine Performance, Earnings, Days with Car and Moove Details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kjvfVgVl0JX"
      },
      "source": [
        "# join elements of the final payments file\n",
        "dfs = [performancefile1,netEarnings, cashCollected]\n",
        "\n",
        "# join on driverUUID\n",
        "reconfile = reduce(lambda left,right: pd.merge(left,right,how='outer', on='driverUUID'), dfs)\n",
        "reconfile = reconfile.fillna(0)\n",
        "\n",
        "dfs = [reconfile,daysWithCar]\n",
        "reconfile = reduce(lambda left,right: pd.merge(left,right,how='outer', on='driverUUID'), dfs)\n",
        "\n",
        "# join on DRN\n",
        "dfs = [reconfile,sumVA, countVA]\n",
        "reconfile = reduce(lambda left,right: pd.merge(left,right,how='left', on='DRN'), dfs)\n",
        "\n",
        "reconfile['Cash Collected'] = -reconfile['Cash Collected'].fillna(0)\n",
        "reconfile['Uber Balance'] = reconfile['Net Earnings'] - reconfile['Cash Collected']\n",
        "reconfile['Effective Days'] = reconfile['Effective Days'].fillna(\"Missing Car Record\")\n",
        "reconfile['Hours online'] = reconfile['Hours online'].fillna(\"Did not work\")\n",
        "reconfile['Trips'] = reconfile['Trips'].fillna(0)\n",
        "reconfile['VA Transactions'] = reconfile['VA Transactions'].fillna(0).astype(int)\n",
        "reconfile['VA Collections'] = reconfile['VA Collections'].fillna(0)\n",
        "reconfile['VA Incentive'] = pd.DataFrame(map(lambda x: 7000 if x >= 20 else x * 100, reconfile['VA Transactions']))\n",
        "\n",
        "reconfile = reconfile[['DRN', 'Name', 'Product', 'Uber Balance', 'Cash Collected', 'VA Collections', 'Net Earnings', \n",
        "        'Trips', 'Hours online', 'VA Transactions','VA Incentive','Effective Days','driverUUID']]\n",
        "\n",
        "reconfile = reconfile.fillna('')\n",
        "reconfile = reconfile.sort_values('Trips',ascending=False)\n",
        "reconfile.head(400)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdByPParSy-8"
      },
      "source": [
        "# # export recon file to csv\n",
        "reconfile_csv = reconfile.to_csv( \"reconfile_TestFinal.csv\", index=False, encoding='utf-8-sig')\n",
        "# reconfile_wk5thJul.csv\n",
        "\n",
        "file2 = drive.CreateFile({'parents': [{'id': '15w_MeKLpCE2hs8-Vvs4IUBH_sZ8e3qbP'}]})\n",
        "file2.SetContentFile(\"reconfile_TestFinal.csv\")\n",
        "file2.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxJ9H_Dgwy5b"
      },
      "source": [
        "# Write recon file to google sheets\n",
        "# reconSheet = client.open_by_key('1hWr33xeKPsgjA5oRjADCFHtH3CkeiebdJ1eMM6IRia0')\n",
        "# wksreconfile = reconSheet[1]\n",
        "\n",
        "# wksreconfile.set_dataframe(reconfile,(1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "093iWsU2fKvE"
      },
      "source": [
        "#  export payments file to csv\n",
        "paymentsCombined_csv = combinedPayments.to_csv( \"paymentsfile_wk5thJul.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "file2 = drive.CreateFile({'parents': [{'id': '15w_MeKLpCE2hs8-Vvs4IUBH_sZ8e3qbP'}]})\n",
        "file2.SetContentFile(\"paymentsfile_wk5thJul.csv\")\n",
        "file2.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeFFymsD4N0R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3cCEe2sS0Rg"
      },
      "source": [
        "Write reconciled files into google sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGCuZX2e8Zr5"
      },
      "source": [
        "# create new sheet for the week\n",
        "\n",
        "weekname = \"May 11\"\n",
        "sh = gc.open_by_key('1Q3BJcXwRncZiiB3GAYw1CNN-RWOWjt4AyUHxjs_Kztg')\n",
        "weeksheet = sh.add_worksheet(title=weekname, rows=\"100\", cols=\"10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrBqyRrhV_uI"
      },
      "source": [
        "weekperformance = pd.merge(wkperffile,mooveDetails, how='left', on='Name')\n",
        "weekperformance = weekperformance[['DRN', 'Name',  'Product', 'Net Fares', 'Per trip', 'Per hour online', 'Per km on trip',\n",
        "       'Trips', 'Hours online', 'Trips per hour', 'Distance per trip',\n",
        "       'Ratings', 'Lifetime rating', 'Acceptance rate',\n",
        "       'Driver cancellation rate' ]]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}